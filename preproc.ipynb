# -*- coding: utf-8 -*-
"""
Created on Sat Jan 11 23:08:25 2020

@author: L
"""
#%% Setup
import os
import pandas as pd
import numpy as np

path = r'C:\Users\L\Google Drive\PhD\experiments\ATTMEM\ATTMEM_pilot_0\experiment\raw_data'

# get all files in folder
files = [f'{path}\\{f}' for f in os.listdir(path) if f.split('.')[-1] == 'log']

#%% Aggregate the data
print("Aggregating data...")
encoding_files = []
retrieval_files = []

for f in files:
    
    # Parse the filename
    fname = f.split('\\')[-1].split('.')[0]
    fparts = fname.split('_')
    subject_number, exp_version = [int(p) for p in fparts[0].split('-')]
    experiment_phase = fparts[2]
    block_number = int(fparts[-1])
    
    # Get the file write date & time
    with open(f) as fp:
        for i, line in enumerate(fp):
            if i == 1:
                if 'Logfile written' in line:
                    date, time = line.strip().split(' ')[-2:]
                break
             
    df = pd.read_csv(f, sep='\t', skiprows=3)
    
    df['write_time'] = date + ' ' + time
    df['write_time'] = pd.to_datetime(df['write_time'])
    df['version'] = exp_version
    df['phase'] = experiment_phase
    df['block'] = block_number
    
    # Strip out first few rows until first stimulus event
    start_idx = df.loc[(df['Event Type']=='Picture') & (df['Code']!='GETTING READY')].index[0]
    df = df.iloc[start_idx:]
    
    
    if experiment_phase == 'encoding':
        encoding_files.append(df)
    elif experiment_phase == 'retrieval':
        retrieval_files.append(df)

# Concatenate all files together
df1 = pd.concat(encoding_files)
df2 = pd.concat(retrieval_files)

#%% Clean up the dataset 
print("Cleansing data...")
# Fix up the column names
df1.columns = [c.replace(' ', '_').replace('(', '_').replace(')', '').lower() for c in df1.columns]
df2.columns = [c.replace(' ', '_').replace('(', '_').replace(')', '').lower() for c in df2.columns]
df1.columns = [c[:-4] if c[-4:]=='_str' else c for c in df1.columns]
df2.columns = [c[:-4] if c[-4:]=='_str' else c for c in df2.columns]

# Drop the MRI pulse trigs
df1 = df1.loc[df1['event_type'] != 'Pulse']
df2 = df2.loc[df2['event_type'] != 'Pulse']


#%% Extract responses and relevant info
# Responses for df1 (encoding)
df1rs = df1.loc[df1['event_type'] == 'Response'][
    ['subject', 'phase', 'block', 'trial', 'code', 'time', 'ttime']
    ].rename(columns={'time':'response_time', 'ttime':'response_ttime'})
# Events for df1 (encoding)
df1es = df1.loc[df1['event_type'] == 'Picture']

# Merge them on common columns
df1 = pd.merge(
    df1es, df1rs, how='left', 
    left_on=['subject', 'phase', 'block', 'trial'],
    right_on=['subject', 'phase', 'block', 'trial']).sort_values(by=['subject', 'write_time'])

# Responses for df2 (retrieval)
df2rs = df2.loc[df2['event_type'] == 'Response'][
    ['subject', 'phase', 'block', 'trial', 'code', 'time', 'ttime']
    ].rename(columns={'time':'response_time', 'ttime':'response_ttime'})
# Events for df2 (retrieval)
df2es = df2.loc[df2['event_type'] == 'Picture']
# Merge them
df2 = pd.merge(df2es, df2rs, how='left', 
                left_on=['subject', 'phase', 'block', 'trial'],
                right_on=['subject', 'phase', 'block', 'trial']).sort_values(by=['subject', 'write_time'])

#%% Re-reference trial numbers
for s in df1['subject'].unique():
    sdf = df1.loc[df1['subject']==s]
    for b in sdf['block'].unique():
        sbdf = sdf.loc[sdf['block']==b]
        to_change = (df1['subject']==s)&(df1['block']==b)
        first = df1.loc[to_change]['trial'].iloc[0]
        df1.loc[to_change, 'trial'] = df1.loc[to_change]['trial'] - (first-1)

for s in df2['subject'].unique():
    sdf = df2.loc[df2['subject']==s]
    for b in sdf['block'].unique():
        sbdf = sdf.loc[sdf['block']==b]
        to_change = (df2['subject']==s)&(df2['block']==b)
        first = df2.loc[to_change]['trial'].iloc[0]
        df2.loc[to_change, 'trial'] = df2.loc[to_change]['trial'] - (first-1)

#%% Recode condition numbers
df1['condition_num'] = df1['condition_num'].astype(int)
df2['condition_num'] = df2['condition_num'].astype(int)

# Encoding phase
df1['attention_mode'] = np.where(df1['condition_num'] < 3, 'search', 'capture')
df1['target_category'] = np.where(df1['condition_num'] % 2 == 0, 'in', 'out')

# Retrieval phase
# Easier to do a different approach
temp = df2.replace({'condition_num' : { 1:'old_search_target', 2:'old_search_distractor',
                                        3:'old_capture_target', 4:'old_capture_distractor', 5:'new__'}})['condition_num']
temp = temp.str.split('_', expand=True).replace('', np.nan).rename(columns={0:'item_category', 
                                                                            1:'attention_mode', 
                                                                            2:'item_type'})
df2 = df2.merge(right=temp, left_index=True, right_index=True)

df2['response'] = df2['code_y'].astype(float)
df2['response'] = np.where(df2['response'].isin([1,2,3,4,5,6]), df2['response'], np.nan)

# df2['judgement'] = df2['response'].copy()
df2['judgement'] = df2['response'].replace({1: 'high_new',
                                  2: 'mid_new',
                                  3: 'low_new',
                                  4: 'low_old',
                                  5: 'mid_old',
                                  6: 'high_old'})

split = df2['judgement'].str.split('_', expand=True)
df2['confidence'] = split[0]
df2['judgement'] = split[1]

df2.loc[(df2['item_category'] == 'old') & (df2['judgement']=='old'), 'response_class'] = 'hit'
df2.loc[(df2['item_category'] == 'old') & (df2['judgement']=='new'), 'response_class'] = 'miss'
df2.loc[(df2['item_category'] == 'new') & (df2['judgement']=='old'), 'response_class'] = 'false_alarm'
df2.loc[(df2['item_category'] == 'new') & (df2['judgement']=='new'), 'response_class'] = 'correct_reject'

# Dummify response_class
dummies = pd.get_dummies(df2['response_class'])
df2 = pd.concat([df2, dummies], axis=1)


#%% Get block order & name of blcok
# # Set the name
df1['block_name'] = df1.replace({'block':{1:'animals', 2:'foods', 3:'techs', 4:'tools'}})['block']
# Sort by write time to get correct order
df1 = df1.sort_values(by=['subject', 'write_time', 'trial']).reset_index(drop=True)
df2 = df2.sort_values(by=['subject', 'write_time', 'trial']).reset_index(drop=True)


#%% Correct the capture time onsets
'''
The code for the experiment incorrectly logged the onset of capture trials
as the return of the flicker stimulus. This flicker period
began at 150 ms post trial onset, and lasted for 150 ms. Therefore the 
following columns need correcting by 300 ms:
    time: stimulus onset time relative to start of experiment
    response_time: response time relative to start of experiment
    response_ttime: response time relative to start of trial
    duration: duration of the trials (increase them by 300 ms)
'''

search_mask = df1['attention_mode'] == 'search'
capture_mask = df1['attention_mode'] == 'capture'

example_search = df1.loc[search_mask]['duration'].iloc[0]
example_capture = df1.loc[capture_mask]['duration'].iloc[0]
tdiff = example_search - example_capture
# Fix attention times here
# Correct time column
df1.loc[capture_mask, 'time'] = df1.loc[capture_mask]['time'] - tdiff # 3000 microseconds.
# Correct the duration col
df1.loc[capture_mask, 'duration'] = df1.loc[capture_mask]['duration'] + tdiff
# Correct response_time col
df1.loc[capture_mask, 'response_time'] = df1.loc[capture_mask]['response_time'] - tdiff
# Correct the response_ttime col
df1.loc[capture_mask, 'response_ttime'] = df1.loc[capture_mask]['response_ttime'] - tdiff # INCORRECT!!! MUST BE `+ tdiff`!!!

#%% Estimate duration taken to search

df1.loc[capture_mask, 'processing_capture'] = df1.loc[capture_mask]['response_ttime']-tdiff
df1['processing_capture'] = df1['processing_capture'].astype(float)
df1['median_capture_rt'] = df1.groupby(
    ['subject', 'block', 'attention_mode']
    )['processing_capture'].transform(np.median)
df1['median_capture_rt'] = df1.groupby(
    ['subject', 'block'])['median_capture_rt'].transform('median')

# Do the same for search trials
df1.loc[search_mask, 'processing_search'] = df1.loc[search_mask]['response_ttime']
df1['processing_search'] = df1['processing_search'].astype(float)
df1['median_search_rt'] = df1.groupby(
    ['subject', 'block', 'attention_mode']
    )['processing_search'].transform(np.median)
df1['median_search_rt'] = df1.groupby(
    ['subject', 'block'])['median_search_rt'].transform('median')

# Collapse them
df1['median_rts'] = np.where(search_mask, df1['median_search_rt'], df1['median_capture_rt'])

# Subtract out the capture response time
df1['search_duration_estimate'] = df1['median_search_rt'] - df1['median_capture_rt']
# and correct the search processing duration
df1['processing_search'] = df1['processing_search'] - df1['search_duration_estimate']
# So now we have the PROCESSING time upon detection of the target...
#   as well as the estimate of how long (median) it takes to search for the target.
df1['corrected_rt'] =  df1['processing_search'].fillna(0) + df1['processing_capture'].fillna(0)
df1 = df1.replace({'corrected_rt': {0: np.nan}})

#%% Rename and then recode temporal columns to be in both ms and s formats
# default should be ms, so no need to append since we will never need Î¼s...
df1_timecols = ['time', 'ttime', 'uncertainty', 'duration',
                'uncertainty.1', 'reqtime', 'reqdur', 'response_time', 
                'response_ttime', 'processing_capture', 'median_capture_rt',
                'processing_search', 'median_search_rt', 'median_rts', 
                'search_duration_estimate', 'corrected_rt']
df2_timecols = df1_timecols[:9]
df1_to_seconds = ['time', 'response_ttime', 'corrected_rt']
df2_to_seconds = df1_to_seconds[:-1]

# Apply the changes
df1[df1_timecols] = df1[df1_timecols].apply(lambda x: x.astype(float) / 10)
df2[df2_timecols] = df2[df2_timecols].apply(lambda x: x.astype(float) / 10)

for c in df1_to_seconds:
    df1[f'{c}_s'] = df1[c].astype(float) / 1000
for c in df2_to_seconds:
    df2[f'{c}_s'] = df2[c].astype(float) / 1000
        

#%% Collecting subsequent memory data from retrieval df into encoding df

enc_stim = df1[['subject', 'block_name', 'trial', 'attention_mode', 
            'target_name', 'dist_1_name', 'dist_2_name', 
            'dist_3_name', 'response_ttime', 'corrected_rt']]
enc_stim = pd.melt(frame=enc_stim,
                   id_vars=['subject', 'block_name', 'attention_mode', 'trial', 'response_ttime', 'corrected_rt'],
                   value_vars=['target_name', 'dist_1_name', 'dist_2_name', 'dist_3_name'],
                   var_name='image_type',
                   value_name='image_name')
# merge retrieval to encoding
ret_stim = df2[['subject', 'block', 'item_type', 'image_name', 'response_class', 'hit', 'miss', 'response_ttime']]

enc_stim = enc_stim.rename(columns={'response_ttime':'encoding_rt'})
ret_stim = ret_stim.rename(columns={'response_ttime':'retrieval_rt'})

smdf = enc_stim.merge(right=ret_stim, on=['subject', 'image_name'])

all_subject_encoding_data = []
# loop over each subject
for s in df1['subject'].unique():
    # create subject views to update - this has to be on a subject-by-subject basis
    # because subjects see the same stimuli, so it won't work otherwise.
    sdf1 = df1.loc[df1['subject']==s].copy()
    sdf2 = df2.loc[df2['subject']==s].copy()
    # create subsequently dropped columns and populate it with the dummy.
    sdf1.loc[~sdf1['target_name'].isin(sdf2['image_name']), 'subsequently_dropped'] = 1
    sdf1.loc[sdf1['target_name'].isin(sdf2['image_name']), 'subsequently_dropped'] = 0
    # Now, in the encoding df, if that encoding target is present in the 
    # retrieval df - AND if it was subsequently a hit, put subsequently remembered.
    sdf1.loc[sdf1['target_name'].isin(sdf2[(sdf2['item_type']=='target') &
             (sdf2['hit']==1)]['image_name']), 'subsequently_remembered'] = 1
    sdf1.loc[sdf1['target_name'].isin(sdf2[(sdf2['item_type']=='target') &
             (sdf2['miss']==1)]['image_name']), 'subsequently_remembered'] = 0 # didn't remember
    
    sdf1.loc[sdf1['target_name'].isin(sdf2[(sdf2['item_type']=='target') &
             (sdf2['hit']==1)]['image_name']), 'subsequently_forgot'] = 0 # didn't forget
    sdf1.loc[sdf1['target_name'].isin(sdf2[(sdf2['item_type']=='target') &
             (sdf2['miss']==1)]['image_name']), 'subsequently_forgot'] = 1
    
    all_subject_encoding_data.append(sdf1)

df1 = pd.concat(all_subject_encoding_data)

#%%
# import seaborn as sns
# sns.barplot(y='response_ttime', hue='block', x='attention_mode', data=df1.loc[df1['subject']==2])
